{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist"
      ],
      "metadata": {
        "id": "eyFE2RDJsbSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MvyNhIXfO4G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
        "sc_X = StandardScaler()\n",
        "\n",
        "\n",
        "def fileFeedforGNN(name):\n",
        "\n",
        "  data = pd.read_table(name)\n",
        "  X_array = data.iloc[:, 0:16].values\n",
        "\n",
        "  # X_array = sc_X.fit_transform(X_array)\n",
        "  # df = pd.DataFrame(data = X_array)\n",
        "\n",
        " \n",
        "  adding_process_list = []\n",
        "  \n",
        "  for i in range(len(data)- 27):\n",
        "    X_array = data.iloc[i:i+28, 0:16].values\n",
        "  \n",
        "    adding_process_list.append(X_array)\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "  y = data.iloc[:,-3].values\n",
        "  \n",
        "  \n",
        "  print(np.unique(y))\n",
        "\n",
        "\n",
        "  graphList = []\n",
        "  X = adding_process_list\n",
        "  for i in range(len(X)):\n",
        "    interList = []\n",
        "    \n",
        "    for j in range(len(X[i])):\n",
        "      \n",
        "      for k in range(len(X[i][j])):\n",
        "        interList.append(X[i][j][k])\n",
        "      interList+=[X[i][j][1],X[i][j][2],X[i][j][3],X[i][j][5],X[i][j][6],X[i][j][7],X[i][j][8],X[i][j][10],X[i][j][11],X[i][j][12],X[i][j][13],X[i][j][15]]\n",
        "    int_array = np.array(interList)\n",
        "    int_array = sc_X.fit_transform(int_array.reshape(28,28))\n",
        "\n",
        "    #print(int_array.reshape(28,28).shape)\n",
        "\n",
        "    \n",
        "\n",
        "    if(y[i] =='bot'):\n",
        "      graphList.append((transform(int_array),0))\n",
        "    elif (y[i] == 'clothes'):\n",
        "      graphList.append((transform(int_array),1))\n",
        "    elif (y[i] == 'plastic'):\n",
        "      graphList.append((transform(int_array),2))\n",
        "    elif (y[i] == 'steel'):\n",
        "      graphList.append((transform(int_array),3))\n",
        "  \n",
        "  return graphList\n",
        "\n",
        "\n",
        "############################## data loading for 3.5 inch#####################\n",
        "\n",
        "graphList_lablight_3_5 = fileFeedforGNN('lablight_3.5_.txt')\n",
        "graphList_night_3_5 = fileFeedforGNN('night_3.5_.txt')\n",
        "graphList_sunny_3_5 = fileFeedforGNN('sunny_3.5_.txt')\n",
        "\n",
        "\n",
        "lablight_train_len = int(len(graphList_lablight_3_5)*0.7)\n",
        "night_train_len = int(len(graphList_night_3_5)*0.7)\n",
        "sunny_tarin_len = int(len(graphList_sunny_3_5)*0.7)\n",
        "\n",
        "\n",
        "batch_size=64\n",
        "test_batch_size=1000\n",
        "\n",
        "random.shuffle(graphList_lablight_3_5)\n",
        "random.shuffle(graphList_night_3_5)\n",
        "random.shuffle(graphList_sunny_3_5)\n",
        "\n",
        "train_loader_lablight_3_5 = torch.utils.data.DataLoader(graphList_lablight_3_5[0:lablight_train_len],batch_size)  \n",
        "test_loader_lablight_3_5 = torch.utils.data.DataLoader(graphList_lablight_3_5[lablight_train_len:],test_batch_size) \n",
        "\n",
        "train_loader_night_3_5 = torch.utils.data.DataLoader(graphList_night_3_5[0:night_train_len],batch_size)  \n",
        "test_loader_night_3_5 = torch.utils.data.DataLoader(graphList_night_3_5[night_train_len:],test_batch_size) \n",
        "\n",
        "train_loader_sunny_3_5 = torch.utils.data.DataLoader(graphList_sunny_3_5[0:sunny_tarin_len],batch_size)  \n",
        "test_loader_sunny_3_5 = torch.utils.data.DataLoader(graphList_sunny_3_5[sunny_tarin_len:],test_batch_size) \n",
        "\n",
        "print(len(graphList_lablight_3_5))\n",
        "print(len(graphList_night_3_5))\n",
        "print(len(graphList_sunny_3_5))\n",
        "\n",
        "\n",
        "\n",
        "############################## data loading for 7 inch#####################\n",
        "\n",
        "graphList_lablight_7= fileFeedforGNN('lablight_7_.txt')\n",
        "graphList_night_7 = fileFeedforGNN('night_7_.txt')\n",
        "graphList_sunny_7 = fileFeedforGNN('sunny_7_.txt')\n",
        "\n",
        "\n",
        "lablight_train_len = int(len(graphList_lablight_7)*0.7)\n",
        "night_train_len = int(len(graphList_night_7)*0.7)\n",
        "sunny_tarin_len = int(len(graphList_sunny_7)*0.7)\n",
        "\n",
        "\n",
        "batch_size=64\n",
        "test_batch_size=1000\n",
        "\n",
        "random.shuffle(graphList_lablight_7)\n",
        "random.shuffle(graphList_night_7)\n",
        "random.shuffle(graphList_sunny_7)\n",
        "\n",
        "train_loader_lablight_7 = torch.utils.data.DataLoader(graphList_lablight_7[0:lablight_train_len],batch_size)  \n",
        "test_loader_lablight_7 = torch.utils.data.DataLoader(graphList_lablight_7[lablight_train_len:],test_batch_size) \n",
        "\n",
        "train_loader_night_7 = torch.utils.data.DataLoader(graphList_night_7[0:night_train_len],batch_size)  \n",
        "test_loader_night_7 = torch.utils.data.DataLoader(graphList_night_7[night_train_len:],test_batch_size) \n",
        "\n",
        "train_loader_sunny_7= torch.utils.data.DataLoader(graphList_sunny_7[0:sunny_tarin_len],batch_size)  \n",
        "test_loader_sunny_7= torch.utils.data.DataLoader(graphList_sunny_7[sunny_tarin_len:],test_batch_size) \n",
        "\n",
        "print(len(graphList_lablight_7))\n",
        "print(len(graphList_night_7))\n",
        "print(len(graphList_sunny_7))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFPDHlGQgJlM",
        "outputId": "0b52ff44-4081-4fb7-c8b1-dca72f60c80d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bot' 'clothes' 'plastic' 'steel']\n",
            "['bot' 'clothes' 'plastic' 'steel']\n",
            "['bot' 'clothes' 'plastic' 'steel']\n",
            "4189\n",
            "3680\n",
            "3667\n",
            "['bot' 'clothes' 'plastic' 'steel']\n",
            "['bot' 'clothes' 'plastic' 'steel']\n",
            "['bot' 'clothes' 'plastic' 'steel']\n",
            "3957\n",
            "3908\n",
            "3550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "class BorisNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BorisNet, self).__init__()\n",
        "        self.fc = nn.Linear(784, 4, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x.view(x.size(0), -1))\n",
        "\n",
        "\n",
        "class BorisConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BorisConvNet, self).__init__()\n",
        "        self.conv = nn.Conv2d(1, 4, 28, stride=1, padding=14)\n",
        "        self.fc = nn.Linear(4 * 4 * 4, 4, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv(x))\n",
        "        x = F.max_pool2d(x, 7)\n",
        "        return self.fc(x.view(x.size(0), -1))\n",
        "\n",
        "class BorisGraphNet(nn.Module):\n",
        "    def __init__(self, img_size=28, pred_edge=False):\n",
        "        super(BorisGraphNet, self).__init__()\n",
        "        self.pred_edge = pred_edge\n",
        "        N = img_size ** 2\n",
        "        self.fc = nn.Linear(N, 4, bias=False)\n",
        "        if pred_edge:\n",
        "            col, row = np.meshgrid(np.arange(img_size), np.arange(img_size))\n",
        "            coord = np.stack((col, row), axis=2).reshape(-1, 2)\n",
        "            coord = (coord - np.mean(coord, axis=0)) / (np.std(coord, axis=0) + 1e-5)\n",
        "            coord = torch.from_numpy(coord).float()  # 784,2\n",
        "            coord = torch.cat((coord.unsqueeze(0).repeat(N, 1,  1),\n",
        "                                    coord.unsqueeze(1).repeat(1, N, 1)), dim=2)\n",
        "            #coord = torch.abs(coord[:, :, [0, 1]] - coord[:, :, [2, 3]])\n",
        "            self.pred_edge_fc = nn.Sequential(nn.Linear(4, 64),\n",
        "                                              nn.ReLU(),\n",
        "                                              nn.Linear(64, 1),\n",
        "                                              nn.Tanh())\n",
        "            self.register_buffer('coord', coord)\n",
        "        else:\n",
        "            # precompute adjacency matrix before training\n",
        "            A = self.precompute_adjacency_images(img_size)\n",
        "            self.register_buffer('A', A)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def precompute_adjacency_images(img_size):\n",
        "        col, row = np.meshgrid(np.arange(img_size), np.arange(img_size))\n",
        "        coord = np.stack((col, row), axis=2).reshape(-1, 2) / img_size\n",
        "        dist = cdist(coord, coord)  \n",
        "        sigma = 0.05 * np.pi\n",
        "        \n",
        "        # Below, I forgot to square dist to make it a Gaussian (not sure how important it can be for final results)\n",
        "        A = np.exp(- dist / sigma ** 2)\n",
        "        print('WARNING: try squaring the dist to make it a Gaussian')\n",
        "            \n",
        "        A[A < 0.01] = 0\n",
        "        A = torch.from_numpy(A).float()\n",
        "\n",
        "        # Normalization as per (Kipf & Welling, ICLR 2017)\n",
        "        D = A.sum(1)  # nodes degree (N,)\n",
        "        D_hat = (D + 1e-5) ** (-0.5)\n",
        "        A_hat = D_hat.view(-1, 1) * A * D_hat.view(1, -1)  # N,N\n",
        "\n",
        "        # Some additional trick I found to be useful\n",
        "        A_hat[A_hat > 0.0001] = A_hat[A_hat > 0.0001] - 0.2\n",
        "\n",
        "        print(A_hat[:4, :4])\n",
        "        return A_hat\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.size(0)\n",
        "        if self.pred_edge:\n",
        "            self.A = self.pred_edge_fc(self.coord).squeeze()\n",
        "\n",
        "        avg_neighbor_features = (torch.bmm(self.A.unsqueeze(0).expand(B, -1, -1),\n",
        "                                 x.view(B, -1, 1)).view(B, -1))\n",
        "        return self.fc(avg_neighbor_features)\n",
        "\n",
        "\n",
        "def train(log_interval,model, device, train_loader, optimizer, epoch):\n",
        "    model = model.double()\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "     \n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval  == 0 and epoch == 150:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                       100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader,epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    if(epoch == 150):\n",
        "\n",
        "      print(\n",
        "          '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "              test_loss, correct, len(test_loader.dataset),\n",
        "              100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mainTrainer(train_loader,test_loader):\n",
        "\n",
        "  epochs = 150\n",
        "  lr = 0.001\n",
        "  pred_edge = False\n",
        "  seed=1\n",
        "  log_interval=200\n",
        "\n",
        "  use_cuda = True\n",
        "\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "  kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "  #model = BorisGraphNet(pred_edge=pred_edge)\n",
        "  model = BorisConvNet()\n",
        "\n",
        "  model.to(device)\n",
        "  print(model)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=1e-1 if model == 'conv' else 1e-4)\n",
        "  print('number of trainable parameters: %d' %\n",
        "        np.sum([np.prod(p.size()) if p.requires_grad else 0 for p in model.parameters()]))\n",
        "\n",
        "  for epoch in range(1, epochs + 1):\n",
        "      train(log_interval,model, device, train_loader, optimizer, epoch)\n",
        "      test(model, device, test_loader,epoch)\n",
        "  print(\"I am done\")\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "# print(\"3.5\")\n",
        "# print(\"train lablight and test lablight\")\n",
        "# mainTrainer(train_loader_lablight_3_5,test_loader_lablight_3_5)\n",
        "# print(\"train lablight and test night\")\n",
        "# mainTrainer(train_loader_lablight_3_5,test_loader_night_3_5)\n",
        "# print(\"train lablight and test sunny\")\n",
        "# mainTrainer(train_loader_lablight_3_5,test_loader_sunny_3_5)\n",
        "# print(\"train night and test night\")\n",
        "# mainTrainer(train_loader_night_3_5,test_loader_night_3_5)\n",
        "# print(\"train night and test lablight\")\n",
        "# mainTrainer(train_loader_night_3_5,test_loader_lablight_3_5)\n",
        "# print(\"train night and test sunny\")\n",
        "# mainTrainer(train_loader_night_3_5,test_loader_sunny_3_5)\n",
        "# print(\"train sunny and test sunny\")\n",
        "# mainTrainer(train_loader_sunny_3_5,test_loader_sunny_3_5)\n",
        "# print(\"train sunny and test night\")\n",
        "# mainTrainer(train_loader_sunny_3_5,test_loader_night_3_5)\n",
        "# print(\"train sunny and test lablight\")\n",
        "# mainTrainer(train_loader_sunny_3_5,test_loader_lablight_3_5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(\"7\")\n",
        "# print(\"train lablight and test lablight\")\n",
        "# mainTrainer(train_loader_lablight_7,test_loader_lablight_7)\n",
        "# print(\"train lablight and test night\")\n",
        "# mainTrainer(train_loader_lablight_7,test_loader_night_7)\n",
        "# print(\"train lablight and test sunny\")\n",
        "# mainTrainer(train_loader_lablight_7,test_loader_sunny_7)\n",
        "# print(\"train night and test night\")\n",
        "# mainTrainer(train_loader_night_7,test_loader_night_7)\n",
        "# print(\"train night and test lablight\")\n",
        "# mainTrainer(train_loader_night_7,test_loader_lablight_7)\n",
        "# print(\"train night and test sunny\")\n",
        "# mainTrainer(train_loader_night_7,test_loader_sunny_7)\n",
        "# print(\"train sunny and test sunny\")\n",
        "# mainTrainer(train_loader_sunny_7,test_loader_sunny_7)\n",
        "# print(\"train sunny and test night\")\n",
        "# mainTrainer(train_loader_sunny_7,test_loader_night_7)\n",
        "# print(\"train sunny and test lablight\")\n",
        "# mainTrainer(train_loader_sunny_7,test_loader_lablight_7)\n",
        "\n",
        "\n",
        "\n",
        "# print(\"3.5 to 7\")\n",
        "# print(\"train lablight and test lablight\")\n",
        "# mainTrainer(train_loader_lablight_3_5,test_loader_lablight_7)\n",
        "# print(\"train lablight and test night\")\n",
        "# mainTrainer(train_loader_lablight_3_5,test_loader_night_7)\n",
        "# print(\"train lablight and test sunny\")\n",
        "# mainTrainer(train_loader_lablight_3_5,test_loader_sunny_7)\n",
        "# print(\"train night and test night\")\n",
        "# mainTrainer(train_loader_night_3_5,test_loader_night_7)\n",
        "# print(\"train night and test lablight\")\n",
        "# mainTrainer(train_loader_night_3_5,test_loader_lablight_7)\n",
        "# print(\"train night and test sunny\")\n",
        "# mainTrainer(train_loader_night_3_5,test_loader_sunny_7)\n",
        "# print(\"train sunny and test sunny\")\n",
        "# mainTrainer(train_loader_sunny_3_5,test_loader_sunny_7)\n",
        "# print(\"train sunny and test night\")\n",
        "# mainTrainer(train_loader_sunny_3_5,test_loader_night_7)\n",
        "# print(\"train sunny and test lablight\")\n",
        "# mainTrainer(train_loader_sunny_3_5,test_loader_lablight_7)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"7 to 3.5\")\n",
        "print(\"train lablight and test lablight\")\n",
        "mainTrainer(train_loader_lablight_7,test_loader_lablight_3_5)\n",
        "print(\"train lablight and test night\")\n",
        "mainTrainer(train_loader_lablight_7,test_loader_night_3_5)\n",
        "print(\"train lablight and test sunny\")\n",
        "mainTrainer(train_loader_lablight_7,test_loader_sunny_3_5)\n",
        "print(\"train night and test night\")\n",
        "mainTrainer(train_loader_night_7,test_loader_night_3_5)\n",
        "print(\"train night and test lablight\")\n",
        "mainTrainer(train_loader_night_7,test_loader_lablight_3_5)\n",
        "print(\"train night and test sunny\")\n",
        "mainTrainer(train_loader_night_7,test_loader_sunny_3_5)\n",
        "print(\"train sunny and test sunny\")\n",
        "mainTrainer(train_loader_sunny_7,test_loader_sunny_3_5)\n",
        "print(\"train sunny and test night\")\n",
        "mainTrainer(train_loader_sunny_7,test_loader_night_3_5)\n",
        "print(\"train sunny and test lablight\")\n",
        "mainTrainer(train_loader_sunny_7,test_loader_lablight_3_5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONGvqSAtkTeo",
        "outputId": "cff1eba6-5776-423b-d706-39ba42b9f55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 to 3.5\n",
            "train lablight and test lablight\n",
            "BorisConvNet(\n",
            "  (conv): Conv2d(1, 4, kernel_size=(28, 28), stride=(1, 1), padding=(14, 14))\n",
            "  (fc): Linear(in_features=64, out_features=4, bias=False)\n",
            ")\n",
            "number of trainable parameters: 3396\n",
            "Train Epoch: 150 [0/2769 (0%)]\tLoss: 0.056663\n",
            "\n",
            "Test set: Average loss: 2.5299, Accuracy: 332/1257 (26%)\n",
            "\n",
            "I am done\n",
            "train lablight and test night\n",
            "BorisConvNet(\n",
            "  (conv): Conv2d(1, 4, kernel_size=(28, 28), stride=(1, 1), padding=(14, 14))\n",
            "  (fc): Linear(in_features=64, out_features=4, bias=False)\n",
            ")\n",
            "number of trainable parameters: 3396\n",
            "Train Epoch: 150 [0/2769 (0%)]\tLoss: 0.056663\n",
            "\n",
            "Test set: Average loss: 2.3448, Accuracy: 302/1104 (27%)\n",
            "\n",
            "I am done\n",
            "train lablight and test sunny\n",
            "BorisConvNet(\n",
            "  (conv): Conv2d(1, 4, kernel_size=(28, 28), stride=(1, 1), padding=(14, 14))\n",
            "  (fc): Linear(in_features=64, out_features=4, bias=False)\n",
            ")\n",
            "number of trainable parameters: 3396\n",
            "Train Epoch: 150 [0/2769 (0%)]\tLoss: 0.056663\n",
            "\n",
            "Test set: Average loss: 2.5550, Accuracy: 243/1101 (22%)\n",
            "\n",
            "I am done\n",
            "train night and test night\n",
            "BorisConvNet(\n",
            "  (conv): Conv2d(1, 4, kernel_size=(28, 28), stride=(1, 1), padding=(14, 14))\n",
            "  (fc): Linear(in_features=64, out_features=4, bias=False)\n",
            ")\n",
            "number of trainable parameters: 3396\n",
            "Train Epoch: 150 [0/2735 (0%)]\tLoss: 0.071365\n",
            "\n",
            "Test set: Average loss: 2.3281, Accuracy: 271/1104 (25%)\n",
            "\n",
            "I am done\n",
            "train night and test lablight\n",
            "BorisConvNet(\n",
            "  (conv): Conv2d(1, 4, kernel_size=(28, 28), stride=(1, 1), padding=(14, 14))\n",
            "  (fc): Linear(in_features=64, out_features=4, bias=False)\n",
            ")\n",
            "number of trainable parameters: 3396\n",
            "Train Epoch: 150 [0/2735 (0%)]\tLoss: 0.071365\n",
            "\n",
            "Test set: Average loss: 2.2120, Accuracy: 351/1257 (28%)\n",
            "\n",
            "I am done\n",
            "train night and test sunny\n",
            "BorisConvNet(\n",
            "  (conv): Conv2d(1, 4, kernel_size=(28, 28), stride=(1, 1), padding=(14, 14))\n",
            "  (fc): Linear(in_features=64, out_features=4, bias=False)\n",
            ")\n",
            "number of trainable parameters: 3396\n",
            "Train Epoch: 150 [0/2735 (0%)]\tLoss: 0.071365\n",
            "\n",
            "Test set: Average loss: 2.6081, Accuracy: 245/1101 (22%)\n",
            "\n",
            "I am done\n",
            "train sunny and test sunny\n",
            "BorisConvNet(\n",
            "  (conv): Conv2d(1, 4, kernel_size=(28, 28), stride=(1, 1), padding=(14, 14))\n",
            "  (fc): Linear(in_features=64, out_features=4, bias=False)\n",
            ")\n",
            "number of trainable parameters: 3396\n",
            "Train Epoch: 150 [0/2485 (0%)]\tLoss: 0.043122\n",
            "\n",
            "Test set: Average loss: 2.2752, Accuracy: 275/1101 (25%)\n",
            "\n",
            "I am done\n",
            "train sunny and test night\n",
            "BorisConvNet(\n",
            "  (conv): Conv2d(1, 4, kernel_size=(28, 28), stride=(1, 1), padding=(14, 14))\n",
            "  (fc): Linear(in_features=64, out_features=4, bias=False)\n",
            ")\n",
            "number of trainable parameters: 3396\n",
            "Train Epoch: 150 [0/2485 (0%)]\tLoss: 0.043122\n",
            "\n",
            "Test set: Average loss: 2.2011, Accuracy: 319/1104 (29%)\n",
            "\n",
            "I am done\n",
            "train sunny and test lablight\n",
            "BorisConvNet(\n",
            "  (conv): Conv2d(1, 4, kernel_size=(28, 28), stride=(1, 1), padding=(14, 14))\n",
            "  (fc): Linear(in_features=64, out_features=4, bias=False)\n",
            ")\n",
            "number of trainable parameters: 3396\n",
            "Train Epoch: 150 [0/2485 (0%)]\tLoss: 0.043122\n",
            "\n",
            "Test set: Average loss: 2.1691, Accuracy: 360/1257 (29%)\n",
            "\n",
            "I am done\n"
          ]
        }
      ]
    }
  ]
}